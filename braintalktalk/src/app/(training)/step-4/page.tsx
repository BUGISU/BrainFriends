"use client";

import React, {
  useState,
  useEffect,
  useCallback,
  useRef,
  useMemo,
  Suspense,
} from "react";
import { useSearchParams, useRouter } from "next/navigation";
import { FaceLandmarker, FilesetResolver } from "@mediapipe/tasks-vision";
import { calculateLipMetrics, LipMetrics } from "@/utils/faceAnalysis";
import { PlaceType } from "@/constants/trainingData";
export const dynamic = "force-dynamic";
// --- ìƒí™© ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° (ê¸°ì¡´ê³¼ ë™ì¼) ---
const FLUENCY_SCENARIOS: Record<
  PlaceType,
  Array<{
    id: number;
    situation: string;
    prompt: string;
    hint: string;
    minDuration: number;
  }>
> = {
  home: [
    {
      id: 1,
      situation: "ì•„ì¹¨ì— ì¼ì–´ë‚¬ì„ ë•Œ",
      prompt: "ì•„ì¹¨ì— ì¼ì–´ë‚˜ì„œ ë¬´ì—‡ì„ í•˜ì‹œë‚˜ìš”? ìˆœì„œëŒ€ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ì¼ì–´ë‚˜ì„œ ì„¸ìˆ˜í•˜ê³ ...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ì €ë… ì‹ì‚¬ ì¤€ë¹„",
      prompt: "ì €ë…ì— ê°€ì¡±ì„ ìœ„í•´ ì–´ë–¤ ìŒì‹ì„ ë§Œë“¤ê³  ì‹¶ìœ¼ì„¸ìš”?",
      hint: "ì˜ˆ: ëœì¥ì°Œê°œë¥¼ ë“ì´ë ¤ë©´...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ì§‘ ì²­ì†Œí•  ë•Œ",
      prompt: "ì§‘ì„ ê¹¨ë—ì´ ì²­ì†Œí•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
      hint: "ì˜ˆ: ë¨¼ì € ë¹—ìë£¨ë¡œ...",
      minDuration: 10,
    },
  ],
  hospital: [
    {
      id: 1,
      situation: "ì ‘ìˆ˜í•  ë•Œ",
      prompt: "ë³‘ì›ì— ì²˜ìŒ ì™”ì„ ë•Œ ì–´ë–»ê²Œ ì ‘ìˆ˜í•˜ë‚˜ìš”?",
      hint: "ì˜ˆ: ë¨¼ì € ì ‘ìˆ˜ì²˜ì— ê°€ì„œ...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ì¦ìƒ ì„¤ëª…",
      prompt: "ì˜ì‚¬ ì„ ìƒë‹˜ê»˜ ì–´ë””ê°€ ì•„í”ˆì§€ ì„¤ëª…í•´ ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ë©°ì¹  ì „ë¶€í„° ë¨¸ë¦¬ê°€...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ì•½êµ­ì—ì„œ",
      prompt: "ì²˜ë°©ì „ì„ ë“¤ê³  ì•½êµ­ì— ê°€ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
      hint: "ì˜ˆ: ì•½ì‚¬ë‹˜ê»˜ ì²˜ë°©ì „ì„ ì£¼ê³ ...",
      minDuration: 10,
    },
  ],
  cafe: [
    {
      id: 1,
      situation: "ìŒë£Œ ì£¼ë¬¸",
      prompt: "ì¹´í˜ì—ì„œ ì¢‹ì•„í•˜ëŠ” ìŒë£Œë¥¼ ì£¼ë¬¸í•´ ë³´ì„¸ìš”.",
      hint: "ì˜ˆ: ë”°ëœ»í•œ ì•„ë©”ë¦¬ì¹´ë…¸ í•œ ì”...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ì¹œêµ¬ì™€ ëŒ€í™”",
      prompt: "ì¹´í˜ì—ì„œ ì¹œêµ¬ë¥¼ ë§Œë‚¬ì„ ë•Œ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ í•˜ê³  ì‹¶ìœ¼ì„¸ìš”?",
      hint: "ì˜ˆ: ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´?...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ì§ì›ì—ê²Œ ìš”ì²­",
      prompt: "ìŒë£Œì— ë¬¸ì œê°€ ìˆì„ ë•Œ ì–´ë–»ê²Œ ë§ì”€í•˜ì‹œê² ì–´ìš”?",
      hint: "ì˜ˆ: ì£„ì†¡í•œë° ì´ ìŒë£Œê°€...",
      minDuration: 10,
    },
  ],
  bank: [
    {
      id: 1,
      situation: "ê³„ì¢Œ ê°œì„¤",
      prompt: "ì€í–‰ì—ì„œ ìƒˆ í†µì¥ì„ ë§Œë“¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
      hint: "ì˜ˆ: ì‹ ë¶„ì¦ì„ ê°€ì§€ê³ ...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ëˆ ì…ê¸ˆ",
      prompt: "ATMì—ì„œ ëˆì„ ì…ê¸ˆí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ì¹´ë“œë¥¼ ë„£ê³ ...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ìƒë‹´ ìš”ì²­",
      prompt: "ì€í–‰ ì§ì›ì—ê²Œ ëŒ€ì¶œ ìƒë‹´ì„ ìš”ì²­í•´ ë³´ì„¸ìš”.",
      hint: "ì˜ˆ: ì•ˆë…•í•˜ì„¸ìš”, ëŒ€ì¶œì— ëŒ€í•´...",
      minDuration: 10,
    },
  ],
  park: [
    {
      id: 1,
      situation: "ì‚°ì±…í•  ë•Œ",
      prompt: "ê³µì›ì—ì„œ ì‚°ì±…í•˜ë©´ì„œ ë³´ì´ëŠ” ê²ƒë“¤ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ë‚˜ë¬´ê°€ ìˆê³ , ê½ƒì´...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ìš´ë™í•  ë•Œ",
      prompt: "ê³µì›ì—ì„œ ì–´ë–¤ ìš´ë™ì„ í•˜ì‹œë‚˜ìš”? ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ë¨¼ì € ì¤€ë¹„ìš´ë™ì„ í•˜ê³ ...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ë‚ ì”¨ ì´ì•¼ê¸°",
      prompt: "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”? ìì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”.",
      hint: "ì˜ˆ: ì˜¤ëŠ˜ì€ ë§‘ê³ ...",
      minDuration: 10,
    },
  ],
  mart: [
    {
      id: 1,
      situation: "ì¥ë³´ê¸°",
      prompt: "ë§ˆíŠ¸ì—ì„œ ì¼ì£¼ì¼ì¹˜ ì¥ì„ ë³´ë ¤ë©´ ë¬´ì—‡ì„ ì‚¬ì•¼ í•˜ë‚˜ìš”?",
      hint: "ì˜ˆ: ì±„ì†Œë‘ ê³ ê¸°, ê·¸ë¦¬ê³ ...",
      minDuration: 10,
    },
    {
      id: 2,
      situation: "ë¬¼ê±´ ì°¾ê¸°",
      prompt: "ë§ˆíŠ¸ ì§ì›ì—ê²Œ ì›í•˜ëŠ” ë¬¼ê±´ ìœ„ì¹˜ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.",
      hint: "ì˜ˆ: ì‹¤ë¡€í•©ë‹ˆë‹¤, ë¼ë©´ì´ ì–´ë””...",
      minDuration: 10,
    },
    {
      id: 3,
      situation: "ê³„ì‚°í•  ë•Œ",
      prompt: "ê³„ì‚°ëŒ€ì—ì„œ ì–´ë–»ê²Œ ê²°ì œí•˜ì‹œë‚˜ìš”?",
      hint: "ì˜ˆ: ì¹´ë“œë¡œ ê²°ì œí• ê²Œìš”...",
      minDuration: 10,
    },
  ],
};

interface FluencyMetrics {
  totalDuration: number;
  speechDuration: number;
  silenceRatio: number;
  averageAmplitude: number;
  peakCount: number;
  fluencyScore: number;
}

// 1ï¸âƒ£ ì‹¤ì œ ë¡œì§ì„ ë‹´ì€ í´ë¼ì´ì–¸íŠ¸ ì»´í¬ë„ŒíŠ¸
function Step4Content() {
  const router = useRouter();
  const searchParams = useSearchParams();
  const place = (searchParams.get("place") as PlaceType) || "home";
  const step3Score = searchParams.get("step3") || "0";

  const [currentIndex, setCurrentIndex] = useState(0);
  const [phase, setPhase] = useState<"ready" | "recording" | "review">("ready");
  const [isMounted, setIsMounted] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioLevel, setAudioLevel] = useState(0);
  const [isFaceReady, setIsFaceReady] = useState(false);

  const [faceMetrics, setFaceMetrics] = useState<LipMetrics>({
    symmetryScore: 100,
    openingRatio: 0,
    isStretched: false,
    deviation: 0,
  });

  const [fluencyResults, setFluencyResults] = useState<FluencyMetrics[]>([]);
  const [currentFluency, setCurrentFluency] = useState<FluencyMetrics | null>(
    null,
  );

  const videoRef = useRef<HTMLVideoElement>(null);
  const landmarkerRef = useRef<FaceLandmarker | null>(null);
  const animationRef = useRef<number | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioAnimationRef = useRef<number | null>(null);
  const amplitudeHistoryRef = useRef<number[]>([]);
  const timerRef = useRef<NodeJS.Timeout | null>(null);

  const scenarios = useMemo(
    () => FLUENCY_SCENARIOS[place] || FLUENCY_SCENARIOS.home,
    [place],
  );
  const currentScenario = scenarios[currentIndex];

  const predictFace = useCallback(() => {
    const video = videoRef.current;
    const landmarker = landmarkerRef.current;
    if (landmarker && video && video.readyState >= 2) {
      const results = landmarker.detectForVideo(video, performance.now());
      if (results.faceLandmarks?.[0]) {
        setFaceMetrics(calculateLipMetrics(results.faceLandmarks[0]));
      }
    }
    animationRef.current = requestAnimationFrame(predictFace);
  }, []);

  const initAudioAnalysis = useCallback(
    (stream: MediaStream) => {
      const audioContext = new AudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);

      audioContextRef.current = audioContext;
      analyserRef.current = analyser;

      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      const updateAudio = () => {
        analyser.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b) / bufferLength;
        setAudioLevel(average);
        if (phase === "recording") amplitudeHistoryRef.current.push(average);
        audioAnimationRef.current = requestAnimationFrame(updateAudio);
      };
      updateAudio();
    },
    [phase],
  );

  useEffect(() => {
    setIsMounted(true);
    let isCancelled = false;

    async function initTracking() {
      try {
        const vision = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm",
        );
        const landmarker = await FaceLandmarker.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
            delegate: "GPU",
          },
          runningMode: "VIDEO",
        });

        if (isCancelled) return;
        landmarkerRef.current = landmarker;

        const stream = await navigator.mediaDevices.getUserMedia({
          video: { aspectRatio: 1.333, width: 320, height: 240 },
          audio: true,
        });

        if (isCancelled) {
          stream.getTracks().forEach((t) => t.stop());
          return;
        }

        streamRef.current = stream;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            setIsFaceReady(true);
            animationRef.current = requestAnimationFrame(predictFace);
          };
        }
        initAudioAnalysis(stream);
      } catch (err) {
        console.error("ì´ˆê¸°í™” ì‹¤íŒ¨:", err);
      }
    }

    initTracking();
    return () => {
      isCancelled = true;
      if (animationRef.current) cancelAnimationFrame(animationRef.current);
      if (audioAnimationRef.current)
        cancelAnimationFrame(audioAnimationRef.current);
      if (timerRef.current) clearInterval(timerRef.current);
      if (streamRef.current)
        streamRef.current.getTracks().forEach((t) => t.stop());
      if (audioContextRef.current) audioContextRef.current.close();
    };
  }, [predictFace, initAudioAnalysis]);

  const startRecording = () => {
    setPhase("recording");
    setRecordingTime(0);
    amplitudeHistoryRef.current = [];
    timerRef.current = setInterval(
      () => setRecordingTime((prev) => prev + 1),
      1000,
    );
  };

  const stopRecording = () => {
    if (timerRef.current) clearInterval(timerRef.current);
    const totalDuration = recordingTime;
    const history = amplitudeHistoryRef.current;

    const silenceThreshold = 15;
    const speechFrames = history.filter((amp) => amp >= silenceThreshold);
    const speechDuration =
      (speechFrames.length / Math.max(history.length, 1)) * totalDuration;
    const silenceRatio =
      ((totalDuration - speechDuration) / Math.max(totalDuration, 1)) * 100;

    let peakCount = 0;
    let inPeak = false;
    for (const amp of history) {
      if (amp > silenceThreshold * 2 && !inPeak) {
        peakCount++;
        inPeak = true;
      } else if (amp < silenceThreshold) {
        inPeak = false;
      }
    }

    const durationScore = Math.min(
      (speechDuration / currentScenario.minDuration) * 50,
      50,
    );
    const silenceScore = Math.max(30 - silenceRatio * 0.5, 0);
    const peakScore = Math.min(peakCount * 2, 20);
    const fluencyScore = Math.round(durationScore + silenceScore + peakScore);

    const metrics = {
      totalDuration,
      speechDuration: Math.round(speechDuration * 10) / 10,
      silenceRatio: Math.round(silenceRatio * 10) / 10,
      averageAmplitude: 0,
      peakCount,
      fluencyScore: Math.min(fluencyScore, 100),
    };

    setCurrentFluency(metrics);
    setFluencyResults((prev) => [...prev, metrics]);
    setPhase("review");
  };

  const handleNext = () => {
    if (currentIndex < scenarios.length - 1) {
      setCurrentIndex((prev) => prev + 1);
      setPhase("ready");
      setCurrentFluency(null);
      setRecordingTime(0);
    } else {
      const avgScore =
        fluencyResults.length > 0
          ? Math.round(
              fluencyResults.reduce((a, b) => a + b.fluencyScore, 0) /
                fluencyResults.length,
            )
          : 0;
      router.push(
        `/step-5?place=${place}&step3=${step3Score}&step4=${avgScore}`,
      );
    }
  };

  if (!isMounted || !currentScenario) return null;

  return (
    <div className="flex flex-col h-full w-full bg-white rounded-[40px] shadow-sm border border-gray-100 overflow-hidden text-black font-sans">
      <header className="px-6 py-4 border-b border-gray-50 flex justify-between items-center">
        <div className="text-left">
          <span className="text-[#DAA520] font-black text-[10px] tracking-widest uppercase block mb-0.5">
            Step 04 â€¢ {place.toUpperCase()}
          </span>
          <h2 className="text-xl font-black text-[#8B4513] tracking-tighter">
            ìœ ì°½ì„± í•™ìŠµ
          </h2>
        </div>
        <div className="flex items-center gap-3">
          <div
            className={`px-3 py-1 rounded-full text-xs font-bold ${phase === "recording" ? "bg-red-100 text-red-600 animate-pulse" : "bg-gray-100 text-gray-500"}`}
          >
            {phase === "recording" ? `ğŸ”´ ${recordingTime}s` : "ëŒ€ê¸°"}
          </div>
          <div className="bg-[#F8F9FA] px-4 py-1.5 rounded-2xl font-black text-lg text-[#DAA520]">
            {currentIndex + 1} / {scenarios.length}
          </div>
        </div>
      </header>

      <div className="flex-1 flex gap-4 p-4 overflow-hidden">
        <aside className="w-64 flex flex-col gap-3">
          <div className="relative bg-black rounded-2xl overflow-hidden aspect-[4/3]">
            <video
              ref={videoRef}
              autoPlay
              playsInline
              muted
              className="w-full h-full object-cover -scale-x-100"
            />
            <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
              <div className="w-16 h-20 border-2 border-dashed border-green-400/50 rounded-full" />
            </div>
          </div>
          <div className="bg-gray-50 rounded-2xl p-3">
            <h4 className="text-[10px] font-black text-gray-400 uppercase tracking-widest mb-2">
              ìŒì„± ë ˆë²¨
            </h4>
            <div className="h-8 bg-gray-200 rounded-full overflow-hidden">
              <div
                className={`h-full transition-all duration-100 ${audioLevel > 30 ? "bg-green-500" : "bg-amber-500"}`}
                style={{ width: `${Math.min(audioLevel, 100)}%` }}
              />
            </div>
          </div>
          <div className="bg-gray-50 rounded-2xl p-3">
            <h4 className="text-[10px] font-black text-gray-400 uppercase tracking-widest mb-2">
              ì•ˆë©´ ë¶„ì„
            </h4>
            <div className="grid grid-cols-2 gap-2 text-xs">
              <div className="text-center">
                <p className="text-gray-400">ëŒ€ì¹­ì§€ìˆ˜</p>
                <p className="font-bold text-emerald-600">
                  {faceMetrics.symmetryScore}%
                </p>
              </div>
              <div className="text-center">
                <p className="text-gray-400">ê°œêµ¬ë„</p>
                <p className="font-bold text-amber-600">
                  {faceMetrics.openingRatio.toFixed(1)}
                </p>
              </div>
            </div>
          </div>
        </aside>

        <main className="flex-1 flex flex-col items-center justify-center space-y-6">
          <div className="w-full max-w-lg text-center space-y-4">
            <div className="inline-block px-4 py-1 bg-amber-100 rounded-full">
              <span className="text-sm font-bold text-amber-700">
                ğŸ­ ìƒí™©: {currentScenario.situation}
              </span>
            </div>
            <div className="bg-gradient-to-br from-[#8B4513] to-[#A0522D] p-6 rounded-[30px] shadow-xl">
              <p className="text-xl font-bold text-white leading-relaxed">
                {currentScenario.prompt}
              </p>
            </div>
            {phase === "ready" && (
              <p className="text-gray-400 text-sm">
                ğŸ’¡ íŒíŠ¸: {currentScenario.hint}
              </p>
            )}
          </div>

          <div className="flex flex-col items-center space-y-4">
            {phase === "ready" && (
              <button
                onClick={startRecording}
                disabled={!isFaceReady}
                className={`w-32 h-32 rounded-full flex flex-col items-center justify-center shadow-xl transition-all ${isFaceReady ? "bg-red-500 text-white hover:scale-105" : "bg-gray-200 text-gray-400"}`}
              >
                <span className="text-4xl mb-1">ğŸ™ï¸</span>
                <span className="text-xs font-black">ì‹œì‘</span>
              </button>
            )}
            {phase === "recording" && (
              <button
                onClick={stopRecording}
                className="w-32 h-32 bg-gray-800 text-white rounded-full flex flex-col items-center justify-center shadow-xl animate-pulse"
              >
                <span className="text-4xl mb-1">â¹ï¸</span>
                <span className="text-xs font-black">ì¢…ë£Œ</span>
              </button>
            )}
            {phase === "review" && currentFluency && (
              <div className="bg-white border-2 border-amber-200 rounded-[30px] p-5 shadow-lg w-full max-w-sm">
                <div className="grid grid-cols-2 gap-3 text-sm mb-4">
                  <div className="text-center p-2 bg-gray-50 rounded-xl">
                    <p className="text-xs text-gray-400">ë°œí™” ì‹œê°„</p>
                    <p className="font-black text-blue-600">
                      {currentFluency.speechDuration}ì´ˆ
                    </p>
                  </div>
                  <div className="text-center p-2 bg-gray-50 rounded-xl">
                    <p className="text-xs text-gray-400">ì¹¨ë¬µ ë¹„ìœ¨</p>
                    <p className="font-black text-amber-600">
                      {currentFluency.silenceRatio}%
                    </p>
                  </div>
                  <div className="text-center p-2 bg-amber-50 rounded-xl col-span-2">
                    <p className="text-xs text-amber-600">ìœ ì°½ì„± ì ìˆ˜</p>
                    <p className="text-2xl font-black text-amber-700">
                      {currentFluency.fluencyScore}ì 
                    </p>
                  </div>
                </div>
                <button
                  onClick={handleNext}
                  className="w-full py-3 bg-[#DAA520] text-white rounded-xl font-black hover:bg-[#B8860B]"
                >
                  {currentIndex < scenarios.length - 1
                    ? "ë‹¤ìŒ ë‹¨ê³„"
                    : "ìµœì¢… ê²°ê³¼ ë³´ê¸°"}
                </button>
              </div>
            )}
          </div>
        </main>
      </div>
    </div>
  );
}

// 2ï¸âƒ£ ë©”ì¸ í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸: Suspense ë˜í•‘
export default function Step4Page() {
  return (
    <Suspense
      fallback={
        <div className="h-screen flex items-center justify-center bg-white">
          <div className="flex flex-col items-center gap-4">
            <div className="w-12 h-12 border-4 border-amber-500 border-t-transparent rounded-full animate-spin" />
            <p className="font-black text-gray-400">
              ìœ ì°½ì„± ë¶„ì„ ì—”ì§„ ë¡œë“œ ì¤‘...
            </p>
          </div>
        </div>
      }
    >
      <Step4Content />
    </Suspense>
  );
}
