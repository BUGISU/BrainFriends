/**
 * ìŒì„± ì¸ì‹ ë° ë°œìŒ ë¶„ì„ ì‹œìŠ¤í…œ
 * - OpenAI Whisper API ì‚¬ìš© (95.2% ì •í™•ë„ ëª©í‘œ)
 * - í…ŒìŠ¤íŠ¸ ëª¨ë“œ(Mock Data) ì§€ì›
 * - ë°œìŒ ì •í™•ë„ ì¸¡ì • ë° ì•ˆë©´ ëŒ€ì¹­ì„± ì—°ë™
 */

export interface SpeechAnalysisResult {
  transcript: string; // ì¸ì‹ëœ í…ìŠ¤íŠ¸
  confidence: number; // 0-1 ì‹ ë¢°ë„
  pronunciationScore: number; // 0-100 ë°œìŒ ì ìˆ˜
  duration: number; // ms
  audioLevel: number; // dB
}

export interface PronunciationMetrics {
  syllableAccuracy: number; // ìŒì ˆ ì •í™•ë„
  tonalAccuracy: number; // ìŒì¡° ì •í™•ë„
  speedRatio: number; // ë°œí™” ì†ë„ (ì •ìƒ ëŒ€ë¹„)
  clarityScore: number; // ëª…ë£Œë„
}

// ============================================================================
// 1. ìŒì„± ë…¹ìŒ ê´€ë¦¬
// ============================================================================

export class AudioRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private stream: MediaStream | null = null;
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private dataArray: Uint8Array | null = null;
  private animationId: number | null = null;

  async startRecording(onAudioLevel?: (level: number) => void): Promise<void> {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000,
        },
      });

      if (onAudioLevel) {
        this.audioContext = new AudioContext();
        this.analyser = this.audioContext.createAnalyser();
        const source = this.audioContext.createMediaStreamSource(this.stream);
        source.connect(this.analyser);
        this.analyser.fftSize = 256;
        this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);

        const updateLevel = () => {
          if (this.analyser && this.dataArray) {
            this.analyser.getByteFrequencyData(this.dataArray);
            const sum = this.dataArray.reduce((a, b) => a + b, 0);
            const average = sum / this.dataArray.length;
            const dB = 20 * Math.log10(average / 255);
            onAudioLevel(Math.max(0, dB + 60));
          }
          this.animationId = requestAnimationFrame(updateLevel);
        };
        updateLevel();
      }

      this.mediaRecorder = new MediaRecorder(this.stream, {
        mimeType: "audio/webm",
      });

      this.audioChunks = [];
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) this.audioChunks.push(event.data);
      };
      this.mediaRecorder.start();
    } catch (error) {
      console.error("ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:", error);
      throw error;
    }
  }

  async stopRecording(): Promise<Blob> {
    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder) {
        reject(new Error("MediaRecorderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."));
        return;
      }
      this.mediaRecorder.onstop = () => {
        const audioBlob = new Blob(this.audioChunks, { type: "audio/webm" });
        this.cleanup();
        resolve(audioBlob);
      };
      this.mediaRecorder.stop();
    });
  }

  private cleanup() {
    if (this.animationId !== null) cancelAnimationFrame(this.animationId);
    if (this.audioContext) this.audioContext.close();
    if (this.stream) this.stream.getTracks().forEach((track) => track.stop());
    this.mediaRecorder = null;
    this.audioChunks = [];
  }
}

// ============================================================================
// 2. Whisper API ì—°ë™ (ì„œë²„ í”„ë¡ì‹œ ì‚¬ìš©)
// ============================================================================

export class WhisperTranscriber {
  private apiKey: string;

  constructor(apiKey: string) {
    this.apiKey = apiKey;
  }

  async transcribe(
    audioBlob: Blob,
  ): Promise<{ text: string; confidence: number }> {
    try {
      const formData = new FormData();
      formData.append("file", audioBlob, "audio.webm");
      formData.append("model", "whisper-1");
      formData.append("language", "ko");
      formData.append("response_format", "verbose_json");

      // ì‹¤ì œ ì„œë²„ì˜ Proxy API í˜¸ì¶œ
      const response = await fetch("/api/proxy/whisper", {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(`ë¶„ì„ ì‹¤íŒ¨: ${errorData.error || response.statusText}`);
      }

      const data = await response.json();
      const confidence =
        data.segments?.reduce(
          (sum: number, seg: any) => sum + (seg.no_speech_prob || 0),
          0,
        ) / (data.segments?.length || 1);

      return {
        text: data.text,
        confidence: 1 - confidence,
      };
    } catch (error) {
      console.error("Whisper ì „ì‚¬ ì‹¤íŒ¨:", error);
      throw error;
    }
  }
}

// ============================================================================
// 3. ë°œìŒ ì •í™•ë„ ì¸¡ì • ë¡œì§
// ============================================================================

export class PronunciationAnalyzer {
  private calculateSimilarity(str1: string, str2: string): number {
    const matrix: number[][] = [];
    for (let i = 0; i <= str1.length; i++) matrix[i] = [i];
    for (let j = 0; j <= str2.length; j++) matrix[0][j] = j;

    for (let i = 1; i <= str1.length; i++) {
      for (let j = 1; j <= str2.length; j++) {
        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;
        matrix[i][j] = Math.min(
          matrix[i - 1][j] + 1,
          matrix[i][j - 1] + 1,
          matrix[i - 1][j - 1] + cost,
        );
      }
    }
    const distance = matrix[str1.length][str2.length];
    const maxLength = Math.max(str1.length, str2.length);
    return maxLength === 0 ? 100 : ((maxLength - distance) / maxLength) * 100;
  }

  private decomposeHangul(text: string): string {
    const cho = [
      "ã„±",
      "ã„²",
      "ã„´",
      "ã„·",
      "ã„¸",
      "ã„¹",
      "ã…",
      "ã…‚",
      "ã…ƒ",
      "ã……",
      "ã…†",
      "ã…‡",
      "ã…ˆ",
      "ã…‰",
      "ã…Š",
      "ã…‹",
      "ã…Œ",
      "ã…",
      "ã…",
    ];
    const jung = [
      "ã…",
      "ã…",
      "ã…‘",
      "ã…’",
      "ã…“",
      "ã…”",
      "ã…•",
      "ã…–",
      "ã…—",
      "ã…˜",
      "ã…™",
      "ã…š",
      "ã…›",
      "ã…œ",
      "ã…",
      "ã…",
      "ã…Ÿ",
      "ã… ",
      "ã…¡",
      "ã…¢",
      "ã…£",
    ];
    const jong = [
      "",
      "ã„±",
      "ã„²",
      "ã„³",
      "ã„´",
      "ã„´ã…ˆ",
      "ã„¶",
      "ã„·",
      "ã„¹",
      "ã„¹ã„±",
      "ã„¹ã…",
      "ã„¹ã…‚",
      "ã„¹ã……",
      "ã„¹ã…Œ",
      "ã„¹ã…",
      "ã„¹ã…",
      "ã…",
      "ã…‚",
      "ã…‚ã……",
      "ã……",
      "ã…†",
      "ã…‡",
      "ã…ˆ",
      "ã…Š",
      "ã…‹",
      "ã…Œ",
      "ã…",
      "ã…",
    ];

    let result = "";
    for (let i = 0; i < text.length; i++) {
      const code = text.charCodeAt(i) - 0xac00;
      if (code >= 0 && code <= 11171) {
        result +=
          cho[Math.floor(code / 588)] +
          jung[Math.floor((code % 588) / 28)] +
          jong[code % 28];
      } else {
        result += text[i];
      }
    }
    return result;
  }

  analyzePronunciation(expected: string, actual: string): PronunciationMetrics {
    const expectedClean = expected.replace(/\s+/g, "").toLowerCase();
    const actualClean = actual.replace(/\s+/g, "").toLowerCase();

    const syllableAccuracy = this.calculateSimilarity(
      this.decomposeHangul(expectedClean),
      this.decomposeHangul(actualClean),
    );
    const wordAccuracy = this.calculateSimilarity(expectedClean, actualClean);
    const speedRatio =
      expectedClean.length === 0
        ? 1
        : actualClean.length / expectedClean.length;
    const clarityScore = syllableAccuracy * 0.6 + wordAccuracy * 0.4;

    return {
      syllableAccuracy,
      tonalAccuracy: wordAccuracy,
      speedRatio,
      clarityScore,
    };
  }
}

// ============================================================================
// 4. í†µí•© ë¶„ì„ê¸° (í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì „í™˜ ë¡œì§ í¬í•¨)
// ============================================================================

export class SpeechAnalyzer {
  private recorder: AudioRecorder;
  private transcriber: WhisperTranscriber;
  private pronunciationAnalyzer: PronunciationAnalyzer;
  private startTime: number = 0;

  constructor(whisperApiKey: string) {
    this.recorder = new AudioRecorder();
    this.transcriber = new WhisperTranscriber(whisperApiKey);
    this.pronunciationAnalyzer = new PronunciationAnalyzer();
  }

  async startAnalysis(onAudioLevel?: (level: number) => void): Promise<void> {
    this.startTime = Date.now();
    await this.recorder.startRecording(onAudioLevel);
  }

  async stopAnalysis(expectedText: string): Promise<SpeechAnalysisResult> {
    const audioBlob = await this.recorder.stopRecording();
    const duration = Date.now() - this.startTime;

    // ğŸ”¹ í™˜ê²½ë³€ìˆ˜ì— ë”°ë¥¸ ëª¨ë“œ ìŠ¤ìœ„ì¹­
    const isDevMode = process.env.NEXT_PUBLIC_DEV_MODE === "true";

    if (isDevMode) {
      console.log(
        "ğŸ› ï¸ [TEST MODE] OpenAIë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šê³  ê°€ì§œ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
      );
      // ë¶„ì„ ì¤‘ì¸ ëŠë‚Œì„ ì£¼ê¸° ìœ„í•œ ì§€ì—° ì‹œê°„
      await new Promise((resolve) => setTimeout(resolve, 1200));

      return {
        transcript: expectedText, // ì‚¬ìš©ìê°€ ì™„ë²½í•˜ê²Œ ë°œìŒí•œ ê²ƒìœ¼ë¡œ ê°€ì •
        confidence: 0.99,
        pronunciationScore: 100,
        duration,
        audioLevel: 45,
      };
    }

    // ğŸ”¹ ì‹¤ì œ ëª¨ë“œ: OpenAI Whisper API í˜¸ì¶œ (ìœ ë£Œ)
    const { text, confidence } = await this.transcriber.transcribe(audioBlob);
    const metrics = this.pronunciationAnalyzer.analyzePronunciation(
      expectedText,
      text,
    );

    return {
      transcript: text,
      confidence,
      pronunciationScore: Math.round(metrics.clarityScore),
      duration,
      audioLevel: 0,
    };
  }
}
